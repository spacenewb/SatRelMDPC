{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25451be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import pandas\n",
    "import warnings\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pysindy as ps\n",
    "from numpy import diff\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import solve_ivp\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from matplotlib.ticker import FormatStrFormatter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f831be4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_dir = \"C:/Users/vvh19/OneDrive/Documents/GitHub/SatRelMDPC/src/matlab/RelOrbSim/Export/\"\n",
    "DataInSI_flag = 1\n",
    "\n",
    "# Import from CSV\n",
    "with open(CSV_dir + 'times.csv', newline='') as csvfile:  \n",
    "    times = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'a_f_RTH.csv', newline='') as csvfile:  \n",
    "    a_f_RTH = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'rho.csv', newline='') as csvfile:  \n",
    "    rho = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'rho_dot.csv', newline='') as csvfile:  \n",
    "    rho_dot = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'rho_dotdot.csv', newline='') as csvfile:  \n",
    "    rho_dotdot = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'kep_T.csv', newline='') as csvfile:  \n",
    "    kep_T = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'kep_C.csv', newline='') as csvfile:  \n",
    "    kep_C = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'params_T.csv', newline='') as csvfile:  \n",
    "    params_T = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "with open(CSV_dir + 'params_C.csv', newline='') as csvfile:  \n",
    "    params_C = np.array(list(csv.reader(csvfile))).astype(float)\n",
    "\n",
    "RawData = [times, a_f_RTH, rho, rho_dot, rho_dotdot, kep_T, kep_C, params_T, params_C]\n",
    "\n",
    "req_lin_int = 100 # Required Linearisation Interval [s] \n",
    "req_samp_t = 0.1 # Required Sampling Time [s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "758dbdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EstimateSindyWithControl_MAPE(RawData, req_lin_int, req_samp_t):\n",
    "    \n",
    "    # Import from CSV\n",
    "    times = RawData[0]\n",
    "    a_f_RTH = RawData[1]\n",
    "    rho = RawData[2]\n",
    "    rho_dot = RawData[3]\n",
    "    rho_dotdot = RawData[4]\n",
    "    kep_T = RawData[5]\n",
    "    kep_C = RawData[6]\n",
    "    params_T = RawData[7]\n",
    "    params_C = RawData[8]\n",
    "    \n",
    "    warnings.filterwarnings('ignore') # Only for now\n",
    "    pandas.set_option(\"display.precision\", 2)\n",
    "    \n",
    "    feature_names = ['x', 'y', 'z', 'vx', 'vy', 'vz', 'ux', 'uy', 'uz']\n",
    "    target_names = ['dx/dt', 'dy/dt', 'dz/dt', 'dvx/dt', 'dvy/dt', 'dvz/dt']\n",
    "    \n",
    "    MU = 3.98600433e+5 # From DE405\n",
    "\n",
    "    # Convert to S.I Units if Flag is up\n",
    "    if DataInSI_flag == 1:\n",
    "        a_f_RTH = a_f_RTH*1e3\n",
    "        rho = rho*1e3\n",
    "        rho_dot = rho_dot*1e3\n",
    "        rho_dotdot = rho_dotdot*1e3\n",
    "        kep_T[:,0] = kep_T[:,0]*1e3\n",
    "        kep_C[:,0] = kep_C[:,0]*1e3\n",
    "        MU = 3.98600433e+5 * 1e9 # From DE405\n",
    "    \n",
    "    ##########################################################################################\n",
    "    # Write code here to resample data into requested sample time and linearisation interval #\n",
    "    ##########################################################################################  \n",
    "    raw_data_samp_t = times.reshape(-1)[1] - times.reshape(-1)[0];\n",
    "    req_samples = np.floor(req_lin_int/req_samp_t) + 1\n",
    "    sampling_ratio = req_samp_t/raw_data_samp_t\n",
    "    \n",
    "    if sampling_ratio < 1:\n",
    "        print(\"Required Sampling Time is Smaller Than Original Data\")\n",
    "    \n",
    "    if np.remainder(sampling_ratio, 1) != 0:\n",
    "        print(\"Required Sampling Time is not an Integer Multiple of Original Sampling Time\")\n",
    "        sampling_ratio = np.floor(req_samp_t/raw_data_samp_t)\n",
    "        eq_req_samp_t = sampling_ratio*raw_data_samp_t\n",
    "        print(\"Setting Equivalent New Sampling Time as: \" + eq_req_samp_t)\n",
    "    else:\n",
    "        eq_req_samp_t = sampling_ratio\n",
    "    \n",
    "    eq_req_samp_t = int(eq_req_samp_t)\n",
    "    \n",
    "    if eq_req_samp_t >= req_lin_int/10:\n",
    "        Eccentricity = np.mean([kep_C[:,1], kep_T[:,1]])\n",
    "        SampleTime = eq_req_samp_t\n",
    "        LinearisationInterval = req_lin_int\n",
    "        return(Eccentricity, SampleTime, LinearisationInterval, math.inf, math.inf)\n",
    "    \n",
    "    times = times.reshape(-1)[0:-1:eq_req_samp_t]\n",
    "    a_f_RTH = a_f_RTH[0:-1:eq_req_samp_t,:]\n",
    "    rho = rho[0:-1:eq_req_samp_t,:]\n",
    "    rho_dot = rho_dot[0:-1:eq_req_samp_t,:]\n",
    "    rho_dotdot = rho_dotdot[0:-1:eq_req_samp_t,:]\n",
    "    kep_T = kep_T[0:-1:eq_req_samp_t,:]\n",
    "    kep_C = kep_C[0:-1:eq_req_samp_t,:]\n",
    "    params_T = params_T[0:-1:eq_req_samp_t,:]\n",
    "    params_C = params_C[0:-1:eq_req_samp_t,:]\n",
    "    \n",
    "    times = times[0:int(2*req_samples)]\n",
    "    a_f_RTH = a_f_RTH[0:int(2*req_samples),:]\n",
    "    rho = rho[0:int(2*req_samples),:]\n",
    "    rho_dot = rho_dot[0:int(2*req_samples),:]\n",
    "    rho_dotdot = rho_dotdot[0:int(2*req_samples),:]\n",
    "    kep_T = kep_T[0:int(2*req_samples),:]\n",
    "    kep_C = kep_C[0:int(2*req_samples),:]\n",
    "    params_T = params_T[0:int(2*req_samples),:]\n",
    "    params_C = params_C[0:int(2*req_samples),:]\n",
    "    ##########################################################################################\n",
    "    \n",
    "    # Divide Data into estimation and verification sets\n",
    "    raw_data_samples = len(times);\n",
    "    \n",
    "    if np.remainder(raw_data_samples, 2) != 0:\n",
    "        raw_times = times.reshape(-1)[:-1]\n",
    "        raw_a_f_RTH = a_f_RTH[:-1,:]\n",
    "        raw_rho = rho[:-1,:]\n",
    "        raw_rho_dot = rho_dot[:-1,:]\n",
    "        raw_rho_dotdot = rho_dotdot[:-1,:]\n",
    "        raw_kep_T = kep_T[:-1,:]\n",
    "        raw_kep_C = kep_C[:-1,:]\n",
    "        raw_params_T = params_T[:-1,:]\n",
    "        raw_params_C = params_C[:-1,:]\n",
    "    else:\n",
    "        raw_times = times.reshape(-1)\n",
    "        raw_a_f_RTH = a_f_RTH\n",
    "        raw_rho = rho\n",
    "        raw_rho_dot = rho_dot\n",
    "        raw_rho_dotdot = rho_dotdot\n",
    "        raw_kep_T = kep_T\n",
    "        raw_kep_C = kep_C\n",
    "        raw_params_T = params_T\n",
    "        raw_params_C = params_C  \n",
    "    \n",
    "    (times, times_valid) = np.split(raw_times, 2)\n",
    "    (a_f_RTH, a_f_RTH_valid) = np.vsplit(raw_a_f_RTH, 2)\n",
    "    (rho, rho_valid) = np.vsplit(raw_rho, 2)\n",
    "    (rho_dot, rho_dot_valid) = np.vsplit(raw_rho_dot, 2)\n",
    "    (rho_dotdot, rho_dotdot_valid) = np.vsplit(raw_rho_dotdot, 2)\n",
    "    (kep_T, kep_T_valid) = np.vsplit(raw_kep_T, 2)\n",
    "    (kep_C, kep_C_valid) = np.vsplit(raw_kep_C, 2)\n",
    "    (params_T, params_T_valid) = np.vsplit(raw_params_T, 2)\n",
    "    (params_C, params_C_valid) = np.vsplit(raw_params_C, 2)\n",
    "    \n",
    "    # Estimate Params from State Measurements\n",
    "    rho_dotdot_homogenous = rho_dotdot - a_f_RTH\n",
    "\n",
    "    # Experimental Assumption --> \"h\" is known\n",
    "    est_kw32 = -1*np.divide(rho_dotdot_homogenous[:,2], rho[:,2])\n",
    "    P_Chaser_est = np.multiply( kep_C[:,0], ( 1 - np.multiply(kep_C[:,1], kep_C[:,1]) ) )\n",
    "    H_Chaser_est = np.sqrt(MU*P_Chaser_est)\n",
    "    W_est = np.divide(est_kw32, (MU / H_Chaser_est**(3/2)))**(2/3)\n",
    "    R_est = np.sqrt(np.divide(H_Chaser_est, W_est))\n",
    "\n",
    "    Times = times.reshape(-1)\n",
    "    DT = Times[1] - Times[0]\n",
    "    R_dot_est = np.gradient(R_est, Times)\n",
    "    W_dot_est = (-2/MU)*np.multiply(H_Chaser_est, est_kw32)\n",
    "\n",
    "    est_kw32_mean = np.mean(est_kw32);     est_kw32_median = np.median(est_kw32)\n",
    "    est_W_mean = np.mean(W_est);           est_W_median = np.median(W_est)\n",
    "    est_dW_mean = np.mean(W_dot_est);      est_dW_median = np.median(W_dot_est)\n",
    "\n",
    "    measured_mean_kw32 = est_kw32_median\n",
    "    measured_mean_W = est_W_median\n",
    "    measured_mean_dW = est_dW_median\n",
    "\n",
    "    k1 = 2*measured_mean_kw32 + measured_mean_W**2   # (2*kw3_2 + w^2)\n",
    "    k2 = measured_mean_W**2 - measured_mean_kw32     # ((w^2 - kw3_2)\n",
    "    k3 = -measured_mean_kw32                         # -(kw3_2)\n",
    "    k4 = measured_mean_dW                            # (dw)\n",
    "    k5 = 2*measured_mean_W                           # (2*w)\n",
    "\n",
    "    initial_guess_trial = np.array([[    0,     0,     0,     1,     0,     0,     0,     0,     0],\n",
    "                                    [    0,     0,     0,     0,     1,     0,     0,     0,     0],\n",
    "                                    [    0,     0,     0,     0,     0,     1,     0,     0,     0],\n",
    "                                    [   k1,    k4,     0,     0,     0,    k5,     1,     0,     0],\n",
    "                                    [  -k4,    k2,     0,     0,   -k5,     0,     0,     1,     0],\n",
    "                                    [    0,     0,    k3,     0,     0,     0,     0,     0,     1]])\n",
    "\n",
    "    # Estimation of System Matrix --> Estimate Params\n",
    "    # Structure the data arrays\n",
    "    X = np.concatenate((rho, rho_dot), axis=1)\n",
    "    X_dot = np.concatenate((rho_dot, rho_dotdot), axis=1)\n",
    "    T = times.reshape(-1) # 0 D Array\n",
    "\n",
    "    # ToDo: Split data into train and test sets\n",
    "    x_train = X\n",
    "    t_train = T\n",
    "    Inputs_train = a_f_RTH\n",
    "    x_dot_precomputed = X_dot\n",
    "    \n",
    "    N_ensembles = 50\n",
    "\n",
    "    dt = (t_train[1]-t_train[0])\n",
    "    identity_library = ps.IdentityLibrary()\n",
    "    identity_library.fit(np.concatenate((x_train, Inputs_train), axis=1))\n",
    "\n",
    "    # differentiation_method = ps.FiniteDifference(order=4) # Good\n",
    "    differentiation_method = ps.SmoothedFiniteDifference(smoother_kws={'window_length': 5}, order=6) # Better\n",
    "\n",
    "    n_features = identity_library.n_output_features_\n",
    "\n",
    "    # Set constraints\n",
    "    n_targets = x_train.shape[1]\n",
    "\n",
    "    # constraint_rhs = np.array([1,1,1,1,1,1,0,0,0, -measured_mean_kw32, 2*measured_mean_W])\n",
    "    constraint_rhs = np.array([1,1,1,1,1,1,0,0,0,k5])\n",
    "\n",
    "    # One row per constraint, one column per coefficient\n",
    "    constraint_lhs = np.zeros((constraint_rhs.size, n_targets * n_features))\n",
    "\n",
    "    # Format:\n",
    "    # constraint_lhs[constraint_number, coefficient_of_which_feature + contribution_to_which_target*n_features] = coefficient_factor\n",
    "    # f:feature, t:target, C:coefficient --> C[f1/t3] = coefficient for contribution of f1 in t3\n",
    "\n",
    "    # constraint_lhs[Constraint_number_in_[constraint_rhs], {f?} + {t?}*n_features] = coefficient_multiplier  # c1\n",
    "\n",
    "    # For vx = ........\n",
    "    constraint_lhs[0, 3+0*n_features] = 1.0 # vx\n",
    "    # For vy = ........\n",
    "    constraint_lhs[1, 4+1*n_features] = 1.0 # vy\n",
    "    # For vz = ........\n",
    "    constraint_lhs[2, 5+2*n_features] = 1.0 # vz\n",
    "    # For ax = ........\n",
    "    constraint_lhs[3, 6+3*n_features] = 1.0 # ux\n",
    "    # For ay = ........\n",
    "    constraint_lhs[4, 7+4*n_features] = 1.0 # uy\n",
    "    # For az = ........\n",
    "    constraint_lhs[5, 8+5*n_features] = 1.0 # uz\n",
    "\n",
    "    # For Combined Constraints\n",
    "    # 1*C(ax/y) + 1*C(ay/x) = 0\n",
    "    constraint_lhs[6, 1+3*n_features] = 1.0 # y\n",
    "    constraint_lhs[6, 0+4*n_features] = 1.0 # x\n",
    "    # 1*C(ax/vy) + 1*C(ay/vx) = 0\n",
    "    constraint_lhs[7, 4+3*n_features] = 1.0 # vy\n",
    "    constraint_lhs[7, 3+4*n_features] = 1.0 # vx\n",
    "    # 1*C(ax/x) + -1*C(ay/y) + 3*C(az/z)= 0\n",
    "    constraint_lhs[8, 0+3*n_features] =  1.0 # x\n",
    "    constraint_lhs[8, 1+4*n_features] = -1.0 # y\n",
    "    constraint_lhs[8, 2+5*n_features] =  3.0 # z\n",
    "\n",
    "    # For 2W Constraint in ax\n",
    "    constraint_lhs[9, 4+3*n_features] = 1.0 # vz\n",
    "\n",
    "    s = math.inf;\n",
    "    f = 1e-2;\n",
    "    # Each row corresponds to a measurement variable and each column to a function \n",
    "    # from the feature library\n",
    "\n",
    "    # States                  x       y       z       dx      dy      dz     ux     uy     uz\n",
    "    a_thresholds = np.abs(np.array([[s,      s,      s,      0,      s,      s,     s,     s,      s],        # vx\n",
    "                                    [s,      s,      s,      s,      0,      s,     s,     s,      s],        # vy\n",
    "                                    [s,      s,      s,      s,      s,      0,     s,     s,      s],        # vz\n",
    "                                    [k1*f,   k4*f,   s,      s,      k5*f,   s,     0,     s,      s],        # ax\n",
    "                                    [k4*f,   k2*f,   s,      k5*f,   s,      s,     s,     0,      s],        # ay\n",
    "                                    [s,      s,      k3*f,   s,      s,      s,     s,     s,      0]     ])) # az\n",
    "\n",
    "    csr3_optimizer = ps.ConstrainedSR3(constraint_rhs=constraint_rhs, \n",
    "                                       constraint_lhs=constraint_lhs,\n",
    "                                       thresholder=\"weighted_l1\",\n",
    "                                       nu=0.0000000001,\n",
    "                                       tol=1e-16,\n",
    "                                       max_iter=100,\n",
    "                                       normalize_columns=False,\n",
    "                                       initial_guess=initial_guess_trial,\n",
    "                                       # trimming_fraction=0.1,\n",
    "                                       fit_intercept=True,\n",
    "                                       inequality_constraints = False,\n",
    "                                       thresholds=a_thresholds,\n",
    "    )\n",
    "\n",
    "    # Fit The Model\n",
    "    model = ps.SINDy(feature_names = feature_names,\n",
    "                     optimizer = csr3_optimizer,\n",
    "                     feature_library = identity_library,\n",
    "                     differentiation_method=differentiation_method,\n",
    "    )\n",
    "    model.fit(x_train, \n",
    "              t=dt, \n",
    "              u=Inputs_train,\n",
    "              ensemble=True,\n",
    "              n_models=N_ensembles,\n",
    "              # n_candidates_to_drop=1, \n",
    "              unbias=True\n",
    "              # quiet=True\n",
    "    )\n",
    "    # Formula\n",
    "        # ax -> (2*kw3_2 + w^2)*x,          dw*y,                0             0        2*w*vy,     1     0     0\n",
    "        # ay ->      -dw*x,            (w^2 - kw3_2)*y,          0          -2*w*vx,       0        0     1     0\n",
    "        # az ->        0                      0              -(kw3_2)*z,       0           0        0     0     1\n",
    "\n",
    "    Model_Coef_List = model.coef_list\n",
    "    Model_Coefs = model.coefficients()\n",
    "\n",
    "    # SysA Bagging from Ensembles Coefficient List\n",
    "    # Compute the average of the coefficients, weighted by the MSE & MAPE on the test data.\n",
    "    MAPE_Train = np.zeros(np.shape(Model_Coef_List)[0])\n",
    "    for i in range(np.shape(Model_Coef_List)[0]):\n",
    "        csr3_optimizer.coef_ = np.asarray(Model_Coef_List)[i, :, :]\n",
    "        # For other metrics for scoring: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "        MAPE_Train[i] = model.score(x_train, t=dt, u=Inputs_train, metric=mean_absolute_percentage_error)\n",
    "    SysA_W_ape = np.average(Model_Coef_List, axis=0, weights=MAPE_Train)\n",
    "    \n",
    "    # Validation\n",
    "    X_valid = np.concatenate((rho_valid, rho_dot_valid), axis=1)\n",
    "    X_dot_valid = np.concatenate((rho_dot_valid, rho_dotdot_valid), axis=1)\n",
    "    T_valid = times_valid.reshape(-1) # 0 D Array\n",
    "    x_test = X_valid\n",
    "    t_test = T_valid\n",
    "    Inputs_test = a_f_RTH_valid\n",
    "    x_dot_precomputed_test = X_dot_valid\n",
    "    \n",
    "    MAPE_Test = model.score(x_test, t=dt, u=Inputs_test, metric=mean_absolute_percentage_error)\n",
    "    \n",
    "    # Define Outputs:\n",
    "    Eccentricity = np.mean([kep_C[:,1], kep_T[:,1]])\n",
    "    SampleTime = dt\n",
    "    LinearisationInterval = Times[-1] - Times[0]\n",
    "    BestMAPE_Train = np.min(MAPE_Train)\n",
    "    return(Eccentricity, SampleTime, LinearisationInterval, BestMAPE_Train, MAPE_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbcdfb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_int_array: [ 10.  20.  30.  40.  50.  60.  70.  80.  90. 100.]\n",
      "samp_time_array: [0.01 0.1  1.  ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\optimizers\\constrained_sr3.py:428: ConvergenceWarning: SR3._reduce did not converge after 100 iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22308/38653896.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mreq_samp_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msamp_time_array\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[1;33m(\u001b[0m\u001b[0mEccentricity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSampleTime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearisationInterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBestMAPE_Train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAPE_Test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEstimateSindyWithControl_MAPE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRawData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq_lin_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq_samp_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mResult_ecc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEccentricity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_22308/3056685539.py\u001b[0m in \u001b[0;36mEstimateSindyWithControl_MAPE\u001b[1;34m(RawData, req_lin_int, req_samp_t)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mcsr3_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel_Coef_List\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m         \u001b[1;31m# For other metrics for scoring: https://scikit-learn.org/stable/modules/model_evaluation.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m         \u001b[0mMAPE_Train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mInputs_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[0mSysA_W_ape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel_Coef_List\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAPE_Train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pysindy\\pysindy.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, x, t, x_dot, u, multiple_trajectories, metric, **metric_kws)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m         \u001b[0mx_dot_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 799\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dot_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mmetric_kws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_process_multiple_trajectories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_absolute_percentage_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;36m0.6198\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     \"\"\"\n\u001b[1;32m--> 257\u001b[1;33m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0m\u001b[0;32m    258\u001b[0m         y_true, y_pred, multioutput)\n\u001b[0;32m    259\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "lin_int_array = np.linspace(10, 100, 10)\n",
    "print(\"lin_int_array: \" + str(lin_int_array))\n",
    "\n",
    "samp_time_array = np.array([0.01, 0.1, 1.0])\n",
    "print(\"samp_time_array: \" + str(samp_time_array))\n",
    "\n",
    "Result_ecc = np.zeros((len(lin_int_array),len(samp_time_array)))\n",
    "Result_Ts = np.zeros((len(lin_int_array),len(samp_time_array)))\n",
    "Result_LI = np.zeros((len(lin_int_array),len(samp_time_array)))\n",
    "Result_MapeTrain = np.zeros((len(lin_int_array),len(samp_time_array)))\n",
    "Result_MapeTest = np.zeros((len(lin_int_array),len(samp_time_array)))\n",
    "        \n",
    "for ii in range(len(lin_int_array)):\n",
    "    for jj in range(len(samp_time_array)):\n",
    "        req_lin_int = lin_int_array[ii]\n",
    "        req_samp_t = samp_time_array[jj]\n",
    "        \n",
    "        (Eccentricity, SampleTime, LinearisationInterval, BestMAPE_Train, MAPE_Test) = EstimateSindyWithControl_MAPE(RawData, req_lin_int, req_samp_t)\n",
    "        \n",
    "        Result_ecc[ii,jj] = Eccentricity\n",
    "        Result_Ts[ii,jj] = SampleTime\n",
    "        Result_LI[ii,jj] = LinearisationInterval\n",
    "        Result_MapeTrain[ii,jj] = BestMAPE_Train\n",
    "        Result_MapeTest[ii,jj] = MAPE_Test\n",
    "\n",
    "Mape_Test_matrix = pandas.DataFrame(Result_MapeTest, columns=map(str, samp_time_array), index=map(str, lin_int_array))\n",
    "print(\"MAPE Score for various Sample Times and Linearisation Intervals:\")\n",
    "print(\"\")\n",
    "print(Mape_Test_matrix)\n",
    "print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
